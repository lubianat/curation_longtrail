---
bibliography: references.bib
---

# The situation

1.  One of the first steps in every research project is to become familiar with the relevant literature. While in some level this is true for all research projects, it is made much more explicit for reviews, be they narrative or systematic ones.

2.  Often - if not always - this curation of the relavant literature generates intermediate products containing organized, tabulated information about the articles of interest. These intermediate tables will then be the basis for preparing experiments or discussing results in a review. In systematic reviews, in particular, the data in these tables are used when articles are considered for inclusion. It is likely that information is collected for a large number of articles even if only a small fraction of the studies end up being included.

3.  Most scientists are already producing these small datasets - most of which, currently, are not made public. When pooled together, this might amount to enormous quantities of high-quality data, curated by people with the relevant local-expertise [@ferguson2014].

# The opportunity

1.  These intermediate tables are a rich source of organized information about the published literature. They are the distilled product of several days of highly-specialized work.

2.  Moreover, they are already organized (the scientists involved needed to organize it for their own projects!), which means they could easily be made available to the community.

3.  Large biocuration databases, like UniProt [*add other examples*], are a core resource of current research. This large amount of hidden small curated datasets, if combined and distributed, could make a similarly huge impact in the flow of scientific information.

# The why

1.  Value. Your work has value: other researchers will love to see your curation, even if it is not perfect. It could save them many hours of work. It makes science more communal, it helps bring scientists who otherwise couldn't participate [@nagaraj2020].

2.  Findability. Google Datasets makes it very easy to find the work (and it indexes Zenodo as one of its sources): others will find, and you will find. Most likely, you (or someone in your research group) will be the ones that will try to use the dataset again. So, in 5 years, when you need, you'll be able to find your curation on Google, instead of spending hours sifting through old e-mails, Google Drive, Dropbox or even hard drives. You are your most likely future collaborator.

3.  Searching and harmonizing many small datasets that are relevant to your research is no small feat. For instance, in comparative neuroanatomy, a researcher has published a [tutorial] (<https://dieterlukas.github.io/data.html>) enumerating the multiple steps one might have to follow to find and gather datasets.

4.  Rewards. A table in Zenodo with a DOI is citable, that's recognition for your valuable work. Empirical research also suggests that publications whose datasets are open are cited more often [@colavizza2020]. In addition, openness is increasingly being recognized as an aspect of scientific work that should be recognized and rewarded [@moher2018].

5.  Quality. Making it public improves the curation quality, thereby in a cascade improving the quality of your own work, because you know someone will be able to use it later.

6.  Knowledge graph. Connecting to Wikidata enables powerful queries via the SPARQL query system. Connecting to Wikidata enables use of the Scholia platform to visualize the topics you have curated. Connecting to Wikidata makes it visible for everyone to improve Academic Search Engines, a systemic change that stands to benefit everyone. Although Wikidata is not yet in widespread use for academic purposes [@mora-cantallops2019], it has a lot of potential [@waagmeester2020].

7.  Policy. Publishers and funders are recognizing the importance of open data and moving in that direction with their policies [@cousijn2018].

# The proposed approach (box)

`Tentei colocar essa parte no frame do FAIR, mas não sei se usar DOIs tá em reusable ou interoperable. De qualquer forma, acho que isso aqui devia ser uma caixinha no artigo, sabe? Separado do texto principal, como um "passo a passo sugerido pra fazer isso com os seus datasets". Por isso eu joguei essa seção pro final e adicionei uns trechos redundantes com o "Why", caso alguém resolva ler só a caixinha.`

1.  Our proposal tries to balance the cost of making these intermediate datasets available with the value for the researchers who performed the data curation and for the scientific community at large [@stieglitz2020]. Hence our focus on systematic reviews, where the data curation is already a necessary step. Because the structured dataset is a side effect of the research project, the only added step is making the dataset available.

2.  Make it public: Nowadays, there are many possibilities for making datasets available. We recommend Zenodo, which will make the dataset citable, with its own DOI. As we mentioned above, the curation of these datasets is specialized work, it is a contribution to the scientific community. Being citable makes it easy for this work to be recognized. Another benefit is that Zenodo datasets are automatically indexed by data-specific search engines, such as Google Datasets.

3.  Make it reusable: Describe datasets with enough information to facilitate reuse. If On a similar note, whenever possible, use unique identifiers (e.g. identify scientific articles by their DOI, instead of a full citation).

4.  Make it interoperable: an extra-step, if you feel comfortable with it, is to add the data to open knowledge repositories, such as Wikidata (wikidata.org), while referencing your publicly available table. This makes your dataset available in a standard format, integrated with data from many other sources.
